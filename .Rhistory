TFb[i]=(quantile(xi,.75)-quantile(xi,.25))/1.34
TFb[i]<-TFb[i]
}
se=sqrt(var(TFb))
Normal=c(TFm-(qnorm(.975)*se),TFm+(qnorm(.975)*se))
Pivotal=c(2*TFm-quantile(TFb,.975),2*TFm-quantile(TFb,.025))
Percentil=c(quantile(TFb,0.025),quantile(TFb,0.975))
TFm #estimaci?n a partir de muestra original
se # error estandar de TFm v?a aproximaci?n Bootstrap
# c?lculo de longitudes de cada intervalo bootstrap
longnormal<-longnormal+Normal[2]-Normal[1]
longpivotal<-longpivotal+Pivotal[2]-Pivotal[1]
longpercentil<-longpercentil+Percentil[2]-Percentil[1]
#c?lculo de la cobertura de cada intervalo bootstrap
if (Normal[1]<TFP & Normal[2]>TFP) countn<-countn+1
if (Percentil[1]<TFP & Percentil[2]>TFP) countper<-countper+1
if (Pivotal[1]<TFP & Pivotal[2]>TFP) countpiv<-countpiv+1
}
muestra<-rnorm(50)
muestra
promedio<-mean(muestra)
vari
promedio<-mean(muestra)
var(muestra)
vari<-(sum((muestra-promedio)**2))/50
var(muestra)
vari<-(sum((muestra-promedio)**2))/50
vari
x<-sum((muestra - promedio)**3 / (n * vari**(3/2)))
n<-50
vari
x<-sum((muestra - promedio)**3 / (n * vari**(3/2)))
x
S<-100 # de simulaciones
B<-1000 #n?mero de muestras bootstrap
for (s in 1:S){
{
for (s in 1:S){
x<-rt(25,3)
TFm=(quantile(x,.75)-quantile(x,.25))/1.34
TFb<-c()
for(i in 1:B)>
}
}
x<-rt(25,3)
TF<-sum((muestra - promedio)**3 / (n * vari**(3/2)))
S<-100 # de simulaciones
B<-1000 #n?mero de muestras bootstrap
TFP=(qt(.75,3)-qt(.25,3))/1.34 # el par?mtero de inter?s
longnormal<-0
longpivotal<-0
longpercentil<-0
countn<-0
countper<-0
countpiv<-0
for (s in 1:S){
x<-rt(25,3)
TFm=(quantile(x,.75)-quantile(x,.25))/1.34
TFb<-c()
for(i in 1:B)
{
xi<-sample(x,25,replace=TRUE)
TFb[i]=(quantile(xi,.75)-quantile(xi,.25))/1.34
TFb[i]<-TFb[i]
}
se=sqrt(var(TFb))
Normal=c(TFm-(qnorm(.975)*se),TFm+(qnorm(.975)*se))
Pivotal=c(2*TFm-quantile(TFb,.975),2*TFm-quantile(TFb,.025))
Percentil=c(quantile(TFb,0.025),quantile(TFb,0.975))
TFm #estimaci?n a partir de muestra original
se # error estandar de TFm v?a aproximaci?n Bootstrap
# c?lculo de longitudes de cada intervalo bootstrap
longnormal<-longnormal+Normal[2]-Normal[1]
longpivotal<-longpivotal+Pivotal[2]-Pivotal[1]
longpercentil<-longpercentil+Percentil[2]-Percentil[1]
#c?lculo de la cobertura de cada intervalo bootstrap
if (Normal[1]<TFP & Normal[2]>TFP) countn<-countn+1
if (Percentil[1]<TFP & Percentil[2]>TFP) countper<-countper+1
if (Pivotal[1]<TFP & Pivotal[2]>TFP) countpiv<-countpiv+1
}
#longitudes promedio
longnormal/S
longpercentil/S
longpivotal/S
#Coberturas
countn/S
countper/S
countpiv/S
S<-100 # de simulaciones
B<-1000 #n?mero de muestras bootstrap
for (s in 1:S){
muestra<-rnorm(50)
promedio<-mean(muestra)
var(muestra)
vari<-(sum((muestra-promedio)**2))/50
TF<-sum((muestra - promedio)**3 / (n * vari**(3/2)))
TFb<-c()
for(i in 1:B)
{
xi<-sample(muestra,50,replace=TRUE)
promedio<-mean(xi)
vari<-(sum((xi-promedio)**2))/50
TFb[i]=sum((xi - promedio)**3 / (n * vari**(3/2)))
TFb[i]<-TFb[i]
}
se=sqrt(var(TFb))
Normal=c(TFm-(qnorm(.975)*se),TFm+(qnorm(.975)*se))
Pivotal=c(2*TFm-quantile(TFb,.975),2*TFm-quantile(TFb,.025))
Percentil=c(quantile(TFb,0.025),quantile(TFb,0.975))
TFm #estimaci?n a partir de muestra original
}
sprintf("El intervalo de confianza es (%.6s)",Normal)
for (s in 1:S){
muestra<-rnorm(50)
promedio<-mean(muestra)
var(muestra)
vari<-(sum((muestra-promedio)**2))/50
TF<-sum((muestra - promedio)**3 / (n * vari**(3/2)))
TFb<-c()
for(i in 1:B)
{
xi<-sample(muestra,50,replace=TRUE)
promedio<-mean(xi)
vari<-(sum((xi-promedio)**2))/50
TFb[i]=sum((xi - promedio)**3 / (n * vari**(3/2)))
TFb[i]<-TFb[i]
}
se=sqrt(var(TFb))
Normal=c(TFm-(qnorm(.975)*se),TFm+(qnorm(.975)*se))
Pivotal=c(2*TFm-quantile(TFb,.975),2*TFm-quantile(TFb,.025))
Percentil=c(quantile(TFb,0.025),quantile(TFb,0.975))
TFm #estimaci?n a partir de muestra original
}
sprintf("El intervalo de confianza es (%.6s,%.6s)",Normal[1],Normal[2])
sprintf("El intervalo de confianza pivotal es (%.6s,%.6s)",Pivotal[1],Pivotal[2])
sprintf("El intervalo de confianza Percentil es (%.6s,%.6s)",Percentil[1],Percentil[2])
for (s in 1:S){
muestra<-rnorm(50)
promedio<-mean(muestra)
var(muestra)
vari<-(sum((muestra-promedio)**2))/50
TF<-sum((muestra - promedio)**3 / (n * vari**(3/2)))
TFb<-c()
for(i in 1:B)
{
xi<-sample(muestra,50,replace=TRUE)
promedio<-mean(xi)
vari<-(sum((xi-promedio)**2))/50
TFb[i]=sum((xi - promedio)**3 / (n * vari**(3/2)))
TFb[i]<-TFb[i]
}
se=sqrt(var(TFb))
Normal=c(TF-(qnorm(.975)*se),TF+(qnorm(.975)*se))
Pivotal=c(2*TF-quantile(TFb,.975),2*TF-quantile(TFb,.025))
Percentil=c(quantile(TFb,0.025),quantile(TFb,0.975))
TFm #estimaci?n a partir de muestra original
}
sprintf("El intervalo de confianza normal es (%.6s,%.6s)",Normal[1],Normal[2])
sprintf("El intervalo de confianza pivotal es (%.6s,%.6s)",Pivotal[1],Pivotal[2])
sprintf("El intervalo de confianza Percentil es (%.6s,%.6s)",Percentil[1],Percentil[2])
S<-100 # de simulaciones
B<-1000 #n?mero de muestras bootstrap
for (s in 1:S){
muestra<-rnorm(50)
x<-exp(muestra)
promedio<-mean(x)
var(x)
vari<-(sum((x-promedio)**2))/50
TF<-sum((x - promedio)**3 / (n * vari**(3/2)))
TFb<-c()
for(i in 1:B)
{
xi<-sample(x,50,replace=TRUE)
promedio<-mean(xi)
vari<-(sum((xi-promedio)**2))/50
TFb[i]=sum((xi - promedio)**3 / (n * vari**(3/2)))
TFb[i]<-TFb[i]
}
se=sqrt(var(TFb))
Normal=c(TF-(qnorm(.975)*se),TF+(qnorm(.975)*se))
Pivotal=c(2*TF-quantile(TFb,.975),2*TF-quantile(TFb,.025))
Percentil=c(quantile(TFb,0.025),quantile(TFb,0.975))
}
sprintf("El intervalo de confianza normal es (%.6s,%.6s)",Normal[1],Normal[2])
sprintf("El intervalo de confianza pivotal es (%.6s,%.6s)",Pivotal[1],Pivotal[2])
sprintf("El intervalo de confianza Percentil es (%.6s,%.6s)",Percentil[1],Percentil[2])
muestra<-rnorm(50)
muestra
promedio<-mean(muestra)
var(muestra)
vari<-(sum((muestra-promedio)**2))/50
n<-50
vari
x<-sum((muestra - promedio)**3 / (n * vari**(3/2)))
x
S<-100 # de simulaciones
B<-1000 #n?mero de muestras bootstrap
for (s in 1:S){
muestra<-rnorm(50)
x<-exp(muestra)
promedio<-mean(x)
var(x)
vari<-(sum((x-promedio)**2))/50
TF<-sum((x - promedio)**3 / (n * vari**(3/2)))
TFb<-c()
for(i in 1:B)
{
xi<-sample(x,50,replace=TRUE)#remuestrear y elevar o elevar y remuestrear
promedio<-mean(xi)
vari<-(sum((xi-promedio)**2))/50
TFb[i]=sum((xi - promedio)**3 / (n * vari**(3/2)))
TFb[i]<-TFb[i]
}
se=sqrt(var(TFb))
Normal=c(TF-(qnorm(.975)*se),TF+(qnorm(.975)*se))
Pivotal=c(2*TF-quantile(TFb,.975),2*TF-quantile(TFb,.025))
Percentil=c(quantile(TFb,0.025),quantile(TFb,0.975))
}
sprintf("El intervalo de confianza normal es (%.6s,%.6s)",Normal[1],Normal[2])
sprintf("El intervalo de confianza pivotal es (%.6s,%.6s)",Pivotal[1],Pivotal[2])
sprintf("El intervalo de confianza Percentil es (%.6s,%.6s)",Percentil[1],Percentil[2])
muestra<-runif(50,0,1)
X1<-max(muestra)
X1
muestra<-runif(50,0,1)
X1<-max(muestra)
X1
TFb<-c()
for(i in 1:B)
{
xi<-sample(muestra,50,replace=TRUE)
#vari<-(sum((xi-promedio)**2))/50
TFb[i]=max(xi)
TFb[i]<-TFb[i]
}
se=sqrt(var(TFb))
Normal=c(X1-(qnorm(.975)*se),X1+(qnorm(.975)*se))
Pivotal=c(2*X1-quantile(TFb,.975),2*X1-quantile(TFb,.025))
Percentil=c(quantile(TFb,0.025),quantile(TFb,0.975))
sprintf("El intervalo de confianza normal es (%.6s,%.6s)",Normal[1],Normal[2])
sprintf("El intervalo de confianza pivotal es (%.6s,%.6s)",Pivotal[1],Pivotal[2])
sprintf("El intervalo de confianza Percentil es (%.6s,%.6s)",Percentil[1],Percentil[2])
library(MASS)
library(ggplot2)
library(tidyverse)
S<-100 # de simulaciones
B<-1000 #n?mero de muestras bootstrap
muestra<-rnorm(100,5,1)
#x<-exp(muestra)
promedio<-sum(muestra)/100
promedio
TF<-exp(promedio)
TFb<-c()
for(i in 1:B)
{
xi<-sample(muestra,100,replace=TRUE)
promedio1<-mean(xi)
#vari<-(sum((xi-promedio)**2))/50
TFb[i]=exp(promedio1)
TFb[i]<-TFb[i]
}
se=sqrt(var(TFb))
Normal=c(TF-(qnorm(.975)*se),TF+(qnorm(.975)*se))
Pivotal=c(2*TF-quantile(TFb,.975),2*TF-quantile(TFb,.025))
Percentil=c(quantile(TFb,0.025),quantile(TFb,0.975))
sprintf("El intervalo de confianza normal es (%.6s,%.6s)",Normal[1],Normal[2])
sprintf("El intervalo de confianza pivotal es (%.6s,%.6s)",Pivotal[1],Pivotal[2])
sprintf("El intervalo de confianza Percentil es (%.6s,%.6s)",Percentil[1],Percentil[2])
#x<-exp(muestra)
#parametro bootstrap
promedio<-sum(muestra)/100
promedio
TF<-exp(promedio)
TFb1<-c()
for(i in 1:B){
xx<-rnorm(100,promedio,1)
promedio1<-sum(xx)/100
TFb1[i]=exp(promedio1)
TFb1[i]<-TFb1[i]
}
se=sqrt(var(TFb1))
Normal=c(TF-(qnorm(.975)*se),TF+(qnorm(.975)*se))
Pivotal=c(2*TF-quantile(TFb1,.975),2*TF-quantile(TFb1,.025))
Percentil=c(quantile(TFb1,0.025),quantile(TFb1,0.975))
sprintf("El intervalo de confianza normal es (%.6s,%.6s)",Normal[1],Normal[2])
sprintf("El intervalo de confianza pivotal es (%.6s,%.6s)",Pivotal[1],Pivotal[2])
sprintf("El intervalo de confianza Percentil es (%.6s,%.6s)",Percentil[1],Percentil[2])
hist(TFb)
hist(TFb1)
hist(TFb,title="Remuestreo")
hist(TFb,main = "Remuestreo")
hist(TFb1,main="Nuevas muestras")
par(mfrow = c(1, 2))
hist(TFb,main = "Remuestreo")
hist(TFb1,main="Nuevas muestras")
library(fitdistrplus)
datosnor<-c(3.23, -2.50, 1.88, -0.68, 4.43, 0.17,
1.03, -0.07, -0.01, 0.76, 1.76, 3.18,
0.33, -0.31, 0.30, -0.61, 1.52, 5.43,
1.54, 2.28, 0.42, 2.33, -1.03, 4.00, 0.39)
ajustenor<- fitdist(data = datosnor,
distr = 'norm',
method = 'mle')
ajustenor
S=1000
A=1
B=3
T<-c()
for(i in 1:S)
{
uniform<-runif(10,1,3)
xmin<-min(uniform)
xmax<-max(uniform)
T[i]=(xmin+xmax)/2
}
varianza<-var(T)
mean<-mean(T)
MSE<-varianza+(mean-(A+B)/2)^2
MSE
MSE(T)
z<-qnorm(.95)
z
z<-qnorm(.95)
z
z<-qnorm(.05)
z
affairs2<-read.csv("pobreza.csv")
gc()
setwd("C:/Users/artur/OneDrive/Documentos/uni/7mo/Terminal")
library(tidyverse)
df1<-read.csv("C:\Users\artur\OneDrive\Documentos\uni\7mo\Terminal\Base de datos\INEGI_exporta_6_8_2023_20_48_44.csv")
df1<-read.csv("C://Users//artur//OneDrive//Documentos//uni//7mo//Terminal//Base_de_datos//INEGI_exporta_6_8_2023_20_48_44.csv")
df1<-read.csv("INEGI_exporta_6_8_2023_20_48_44.csv")
df1<-read.csv("C:\Users\artur\OneDrive\Documentos\uni\7mo\Terminal\Base_de_datos\game_data_all")
df1<-read.csv("C://Users//artur//OneDrive//Documentos//uni//7mo//Terminal//Base_de_datos//game_data_all")
setwd("C:/Users/artur/OneDrive/Documentos/uni/7mo/Terminal")
df1<-read.csv("C://Users//artur//OneDrive//Documentos//uni//7mo//Terminal//Base_de_datos//game_data_all")
x<-1
df1<-read.csv("C://Users//artur//OneDrive//Documentos//uni//7mo//Terminal//Base_de_datos//game_data_all.csv")
activision<-df1$primary_genre=="activision"
activision
activision<-df1$primary_genre=="Activision"
activision
activision<-subset(df1,developer=="Activision")
View(activision)
activision<-subset(df1,publisher=="Activision")
View(activision)
summary(activision$rating)
activision
View(activision)
histogram(activision$rating)
his(activision$rating)
hist(activision$rating)
hist(activision$rating,main="Ranking de activision")
hist(activision$rating,main="Ranking de activision",col=rainbow(10))
hist(activision$rating,xlabel="porcentaje",main="Ranking de activision",col=rainbow(10))
hist(activision$rating,xlabel="porcentaje",main="Ranking de activision",col=rainbow(10))
hist(activision$rating,xlab="porcentaje",main="Ranking de activision",col=rainbow(10))
ggplot(activision,aes()
geom_point())
ggplot(activision,
aes(activision$rating)
geom_point())
ggplot(activision,
aes(y=activision$rating,x=length(activision$rating))
geom_point())
ggplot(activision,
aes(y=activision$rating,x=length(activision$rating))
geom_point())
ggplot(activision,
aes(y=activision$rating,x=length(activision$rating))+
geom_point())
ggplot(activision,
aes()+
geom_point())
ggplot(activision+
aes()+
geom_point())
ggplot(activision,
aes()+
geom_point())
ggplot(activision,
aes(y=rating,x=length(activision))
geom_point())
ggplot(activision,
aes(y=rating,x=length(activision))+
geom_point())
ggplot(activision,
aes_(y=rating,x=length(activision))+
geom_point())
ggplot(activision,
aes_(y=activision$rating,x=length(activision))+
geom_point())
ggplot(activision,
aes(y=activision$rating,x=length(activision))+
geom_point())
ggplot(activision,
aes(x=activision$rating,y=length(activision))+
geom_point())
ggplot(activision,
aes(x=rating,y=length(activision))+
geom_point())
ggplot(activision,
aes(x=rating,y=length(activision)))+
geom_point()
ggplot(activision,
aes(x=rating,y=[1:length(activision)]))+
geom_point()
ggplot(activision,
aes(x=rating,y=[1:length(activision)]))+
geom_point()
n<-c(1:length(activision))
ggplot(activision,
aes(x=rating,y=n))+
geom_point()
activision$rating
class(activision$rating)
class(n)
n<-numeric(c(1:length(activision)))
n<-numeric()
n<-numeric(20)
n<-c(1:length(activision))
ggplot(activision,
aes(x=rating,y=n))+
geom_point()
length(activision$rating)
n<-c(1:length(activision$rating))
ggplot(activision,
aes(x=rating,y=n))+
geom_point()
ggplot(activision,
aes(y=rating,x=n,col=ra))+
geom_point()
ggplot(activision,
aes(y=rating,x=n))+
geom_point()
ggplot(activision,
aes(y=rating,x=n))+
geom_point()+
geom_boxplot()
ggplot(activision,
aes(ranking))+
geom_boxplot()
ggplot(activision,
aes(y=ranking))+
geom_boxplot()
ggplot(activision,
aes(y=ranting))+
geom_boxplot()
ggplot(activision,
aes(y=rating))+
geom_boxplot()
#5 numeros y la media
summary(activision$rating)
hist(activision$rating,xlab="porcentaje",main="Ranking de activision",col=rainbow(10))
ran_ecdf<-ecdf(activision$rating)
lot(ran_ecdf, verticals=TRUE, do.points=FALSE, main="distribucion empirica de las calificaciones",
xlab="numero de juego", ylab=" funcion de distribución empirica",
col="black")
plot(ran_ecdf, verticals=TRUE, do.points=FALSE, main="distribucion empirica de las calificaciones",
xlab="numero de juego", ylab=" funcion de distribución empirica",
col="black")
#intervalo de confianza al 95%
alpha <-0.05
en <- sqrt(log(2/alpha)/(2*n))
L_DKW <- pmax(ran_ecdf(activision$rating)-en,0)
U_DKW <- pmin(ran_ecdf(activision$rating)+en,1)
points(sort(tpoesp), L_DKW[order(tpoesp)], "l", col="red")
ranking<-activision$rating
df1<-read.csv("C://Users//artur//OneDrive//Documentos//uni//7mo//Terminal//Base_de_datos//game_data_all.csv")
df1<-read.csv("C://Users//artur//OneDrive//Documentos//uni//7mo//Terminal//Base_de_datos//game_data_all.csv")
activision<-subset(df1,publisher=="Activision")
View(activision)
ranking<-activision$rating
#5 numeros y la media
summary(ranking)
#histograma
hist(ranking,xlab="porcentaje",main="Ranking de activision",col=rainbow(10))
n<-numeric(20)
n<-c(1:length(ranking))
#Dispersion de las calificaciones a los juegos
ggplot(activision,
aes(y=rating,x=n))+
geom_point()
#Dispersion de las calificaciones a los juegos
ggplot(activision,
aes(y=rating,x=n,col=blues9))+
geom_point()
#Dispersion de las calificaciones a los juegos
ggplot(activision,
aes(y=rating,x=n,col=blue))+
geom_point()
#Dispersion de las calificaciones a los juegos
ggplot(activision,
aes(y=rating,x=n,col="blue"))+
geom_point()
#boxplot de la calificacion de los juegos
ggplot(activision,
aes(y=rating))+
geom_boxplot()
ran_ecdf<-ecdf(ranking)
plot(ran_ecdf, verticals=TRUE, do.points=FALSE, main="distribucion empirica de las calificaciones",
xlab="calificacion del juego", ylab=" funcion de distribución empirica",
col="black")
#intervalo de confianza al 95%
alpha <-0.05
en <- sqrt(log(2/alpha)/(2*n))
L_DKW <- pmax(ran_ecdf(ranking)-en,0)
U_DKW <- pmin(ran_ecdf(ranking)+en,1)
points(sort(ranking), L_DKW[order(ranking)], "l", col="red")
points(sort(ranking), U_DKW[order(ranking)], "l", col="red")
lines(c(.5,.5), c(0,1))
